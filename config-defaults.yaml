# Basic HP
tag:
  desc: wandb tags
  value:
    - Debug
model_type:
  desc: which model to use (TCN/MLP/RNN)
  value: TCN
epochs:
  desc: Number of epochs to train over
  value: 600
batch_size:
  desc: Size of each mini-batch
  value: 8192
learning_rate:
  desc: initial learning rate
  value: 0.001
optim:
  desc: optimizer to use
  value: Adam
n_features:
  desc: number of features to include (max 40)
  value: 40

# TCN HP
levels:
  desc: num of tcn blocks
  value: 10
ksize:
  desc: kernel size (smallest is 2)
  value: 3
nhid:
  desc: number of filters
  value: 40
seq_len:
  desc: size of sequence (Be 1 for MLP)
  value: 10

# MLP
layers:
  desc: MLP layers
  value: 1
hidden_units:
  desc: number hidden nodes in layer
  value: 100

# Regularizer
dropout:
  desc: dropout applied to layers
  value: 0.5
weight_decay:
  desc: L2 regularizing
  value: 0.0001

# Cross Validation
cross_validation:
  desc: if crossval should be performed
  value: False
n_splits:
  desc: number of splits
  value: 10

# Environment
skorch:
  desc: if skorch should be used to train (Faster, fewer metrics)
  value: True
flare_label:
  desc: Types of flare class
  value: M5
seed:
  desc: random seed
  value: 50
cuda:
  desc: enables cuda training
  value: True
early_stop:
  desc: stops training if overfitting
  value: True
patience:
  desc: amount of epochs for early stopping
  value: 40
training:
  desc: Trains models, else only tests
  value: True
model_name:
  dsec: The model used for evaluation (if training disabled, 1_100_8192_1e-3)
  value: dewald123/liu_pytorch_MLP/ogkzvcf0
num_workers:
  desc: number of gpu workers
  value: 9


